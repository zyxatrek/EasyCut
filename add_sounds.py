from dataclasses import dataclass
import asyncio
import os
import subprocess
from typing import Optional
import edge_tts
from pydub import AudioSegment
import json
from config import AudioConfig, SubtitleConfig

class AudioProcessor:
    """éŸ³é¢‘å¤„ç†å™¨ç±»"""
    def __init__(self):
        self.audio_config = AudioConfig()
        self.subtitle_config = SubtitleConfig()
        
    async def generate_voice(self, text: str, output_path: str) -> str:
        """ç”Ÿæˆè¯­éŸ³æ–‡ä»¶
        
        Args:
            text: è¦è½¬æ¢çš„æ–‡æœ¬
            output_path: è¾“å‡ºæ–‡ä»¶è·¯å¾„
            
        Returns:
            str: ç”Ÿæˆçš„è¯­éŸ³æ–‡ä»¶è·¯å¾„
        """
        try:
            communicate = edge_tts.Communicate(
                text,
                self.audio_config.voice_name,
                rate=self.audio_config.voice_rate
            )
            await communicate.save(output_path)
            
            if self.audio_config.volume != 1.0:
                self._adjust_volume(output_path)
                
            return output_path
            
        except Exception as e:
            raise RuntimeError(f"ç”Ÿæˆè¯­éŸ³å¤±è´¥: {str(e)}")

    def _adjust_volume(self, audio_path: str) -> None:
        """è°ƒæ•´éŸ³é¢‘æ–‡ä»¶éŸ³é‡
        
        Args:
            audio_path: éŸ³é¢‘æ–‡ä»¶è·¯å¾„
        """
        audio = AudioSegment.from_file(audio_path)
        audio = audio + (20 * self.audio_config.volume)
        audio.export(audio_path, format=self.audio_config.output_format)

    def merge_audio_video(self, video_path: str, audio_path: str, output_path: str) -> str:
        """åˆå¹¶éŸ³é¢‘å’Œè§†é¢‘
        
        Args:
            video_path: è§†é¢‘æ–‡ä»¶è·¯å¾„
            audio_path: éŸ³é¢‘æ–‡ä»¶è·¯å¾„
            output_path: è¾“å‡ºæ–‡ä»¶è·¯å¾„
            
        Returns:
            str: è¾“å‡ºè§†é¢‘æ–‡ä»¶è·¯å¾„
        """
        try:
            cmd = [
                "ffmpeg", "-y",
                "-i", video_path,
                "-i", audio_path,
                "-map", "0:v",
                "-map", "1:a",
                "-c:v", "copy",
                "-shortest",
                output_path
            ]
            
            subprocess.run(cmd, check=True, capture_output=True)
            return output_path
            
        except subprocess.CalledProcessError as e:
            raise RuntimeError(f"åˆå¹¶éŸ³è§†é¢‘å¤±è´¥: {e.stderr.decode()}")

    async def generate_voice_with_timing(self, text: str, output_path: str) -> tuple[str, list]:
        """ç”Ÿæˆè¯­éŸ³æ–‡ä»¶å¹¶è¿”å›æ—¶é—´è½´ä¿¡æ¯"""
        communicate = edge_tts.Communicate(text, self.audio_config.voice_name, rate=self.audio_config.voice_rate)
        
        # ä¿å­˜éŸ³é¢‘
        await communicate.save(output_path)
        
        # åˆ›å»ºæ–°çš„é€šä¿¡å®ä¾‹æ¥è·å–æ—¶é—´è½´ä¿¡æ¯
        communicate = edge_tts.Communicate(text, self.audio_config.voice_name, rate=self.audio_config.voice_rate)
        
        # æ”¶é›†æ—¶é—´è½´ä¿¡æ¯
        word_timings = []
        current_sentence = []
        sentences = self._split_into_sentences(text)
        print(f"ğŸ‚å¤„ç†è§†é¢‘å­—å¹•: {sentences}")
        current_sentence_text = ""
        
        async for event in communicate.stream():
            if event["type"] == "WordBoundary":
                word_timings.append({
                    "word": event["text"],
                    "start": event["offset"] / 10000000,
                    "end": (event["offset"] + event["duration"]) / 10000000
                })
                
        # å°†å•è¯æ—¶é—´è½´ä¿¡æ¯åˆå¹¶ä¸ºå¥å­æ—¶é—´è½´
        sentence_timings = []
        word_index = 0
        
        for sentence in sentences:
            sentence_words = sentence.split()
            if not sentence_words:
                continue
                
            start_time = word_timings[word_index]["start"]
            while word_index < len(word_timings) and len(sentence_words) > 0:
                word_index += 1
                sentence_words.pop(0)
                
            end_time = word_timings[min(word_index - 1, len(word_timings) - 1)]["end"]
            
            sentence_timings.append({
                "word": sentence,
                "start": start_time,
                "end": end_time
            })
        
        return output_path, sentence_timings

    def generate_subtitle_file(self, timings: list, output_path: str):
        """ç”ŸæˆASSå­—å¹•æ–‡ä»¶"""
        ass_content = f"""[Script Info]
ScriptType: v4.00+
PlayResX: 1920
PlayResY: 1080

[V4+ Styles]
Format: Name, Fontname, Fontsize, PrimaryColour, SecondaryColour, OutlineColour, BackColour, Bold, Italic, Underline, StrikeOut, ScaleX, ScaleY, Spacing, Angle, BorderStyle, Outline, Shadow, Alignment, MarginL, MarginR, MarginV, Encoding
Style: Default,{self.subtitle_config.font_path},{self.subtitle_config.font_size},&H0000FFFF,&H000000FF,&H00000000,&H00000000,0,0,0,0,100,100,0,0,1,{self.subtitle_config.outline_width},0,2,10,10,10,1

[Events]
Format: Layer, Start, End, Style, Name, MarginL, MarginR, MarginV, Effect, Text
"""
        # ç”Ÿæˆå­—å¹•å†…å®¹
        for timing in timings:
            start_time = self._format_time(timing["start"])
            end_time = self._format_time(timing["end"])
            text = timing["word"]
            ass_content += f"Dialogue: 0,{start_time},{end_time},Default,,0,0,0,,{text}\n"
            
        with open(output_path, "w", encoding="utf-8") as f:
            f.write(ass_content)
        
        return output_path

    def _format_time(self, seconds: float) -> str:
        """å°†ç§’æ•°è½¬æ¢ä¸ºASSæ—¶é—´æ ¼å¼ (H:MM:SS.cc)"""
        hours = int(seconds / 3600)
        minutes = int((seconds % 3600) / 60)
        seconds = seconds % 60
        centiseconds = int((seconds % 1) * 100)
        seconds = int(seconds)
        return f"{hours}:{minutes:02d}:{seconds:02d}.{centiseconds:02d}"

    def process_video(self, video_path: str, text: str, output_path: str) -> str:
        """å¤„ç†è§†é¢‘ï¼šç”Ÿæˆé…éŸ³å¹¶åˆå¹¶
        
        Args:
            video_path: è¾“å…¥è§†é¢‘è·¯å¾„
            text: é…éŸ³æ–‡æœ¬
            output_path: è¾“å‡ºè§†é¢‘è·¯å¾„
            
        Returns:
            str: å¤„ç†åçš„è§†é¢‘è·¯å¾„
        """
        temp_audio = "temp_voice.mp3"
        try:
            asyncio.run(self.generate_voice(text, temp_audio))
            result = self.merge_audio_video(video_path, temp_audio, output_path)
            return result
        finally:
            if os.path.exists(temp_audio):
                os.remove(temp_audio)

    def process_video_with_subtitle(self, video_path: str, text: str, output_path: str) -> str:
        """å¤„ç†è§†é¢‘ï¼šç”Ÿæˆé…éŸ³ã€å­—å¹•å¹¶åˆå¹¶"""
        temp_audio = "temp_voice.mp3"
        temp_subtitle = "temp_subtitle.ass"
        
        try:
            # ç”Ÿæˆè¯­éŸ³å’Œæ—¶é—´è½´ä¿¡æ¯
            audio_path, timings = asyncio.run(self.generate_voice_with_timing(text, temp_audio))
            
            # ç”Ÿæˆå­—å¹•æ–‡ä»¶
            subtitle_path = self.generate_subtitle_file(timings, temp_subtitle)
            
            # åˆå¹¶è§†é¢‘ã€éŸ³é¢‘å’Œå­—å¹•
            cmd = [
                "ffmpeg", "-y",
                "-i", video_path,
                "-i", audio_path,
                "-vf", f"ass={subtitle_path}",
                "-map", "0:v",
                "-map", "1:a",
                "-c:a", "aac",
                output_path
            ]
            
            subprocess.run(cmd, check=True, capture_output=True)
            return output_path
            
        finally:
            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            for temp_file in [temp_audio, temp_subtitle]:
                if os.path.exists(temp_file):
                    os.remove(temp_file)

    def _split_into_sentences(self, text: str) -> list[str]:
        """å°†æ–‡æœ¬åˆ†å‰²ä¸ºå¥å­
    
        Args:
            text: è¾“å…¥æ–‡æœ¬
    
        Returns:
            list[str]: å¥å­åˆ—è¡¨
        """
        import re
        # åœ¨æ ‡ç‚¹ç¬¦å·å¤„åˆ†å‰²æ–‡æœ¬
        sentences = re.split(r'([,.!?])', text)
        # å°†æ ‡ç‚¹ç¬¦å·é™„åŠ åˆ°å‰ä¸€ä¸ªå¥å­
        result = []
        i = 0
        while i < len(sentences):
            if i + 1 < len(sentences) and sentences[i+1].strip() in [',', '.', '!', '?']:
                # å¦‚æœä¸‹ä¸€ä¸ªå…ƒç´ æ˜¯æ ‡ç‚¹ç¬¦å·ï¼Œå°†å…¶ä¸å½“å‰å¥å­åˆå¹¶
                result.append(sentences[i].strip() + sentences[i+1])
                i += 2
            else:
                # å¤„ç†æœ€åä¸€ä¸ªæ²¡æœ‰æ ‡ç‚¹ç¬¦å·çš„å¥å­
                current = sentences[i].strip()
                if current:
                    result.append(current)
                i += 1
            
        return [s.strip() for s in result if s.strip()]